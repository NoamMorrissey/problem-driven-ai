---
title: "Phase 01: Problem Discovery"
slug: problem-discovery
description: "The art of understanding before solving. The phase where the team commits to understanding the real problem before thinking about solutions."
sidebar_position: 2
tags: [phases, discovery, problem-statement, active-listening, research]
---

# Phase 01: Problem Discovery

## The art of understanding before solving

> *"If I had an hour to solve a problem, I'd spend 55 minutes thinking about the problem and 5 minutes thinking about the solution."*
> — Albert Einstein (attributed)

---

## 1. Why this phase exists

There's a scene that repeats in nearly every organization we've encountered. Someone walks into a meeting with an idea. The idea sounds good. Someone with authority says it seems interesting. Within days, there's a team assigned, a backlog created, and a sprint planned. Nobody stopped to ask whether the problem that idea was supposed to solve actually existed, or whether it existed in the way it was assumed.

With the arrival of generative AI, this dynamic has accelerated. Now you can have a working prototype in hours. An MVP in days. The temptation to jump straight to building is stronger than ever, because the perceived cost of building has plummeted. But the cost of building the wrong thing remains exactly the same. Or worse: now you produce the wrong solution faster, with a higher level of polish, and therefore with greater difficulty for anyone to dare question whether it actually solves anything.

Problem Discovery exists to interrupt that pattern. It's the phase where the team forces itself to understand the real problem before thinking about solutions. It's not a kickoff meeting. It's not a briefing. It's not a form someone fills out to check a box. It's an active, rigorous, and often uncomfortable investigation with the people who live the problem every day.

Its sole objective is to produce a problem definition that is **precise, shared, and validated.** Nothing more. And nothing less.

:::tip Principle 01: The problem is sacred
**The problem is sacred.** Never assume you understand the problem. The real problem is rarely the problem presented to you in the first conversation. You have to earn it through active listening, observation, and uncomfortable questions. A misunderstood problem contaminates everything that follows, without exception.
:::

This phase is the most counterintuitive in the entire methodology. In a world that rewards speed, asking the team to stop and think before acting seems like a luxury. It isn't. It's the highest-return investment in the entire process. Every hour invested in properly understanding the problem saves weeks of misguided building, rework cycles, realignment meetings, and above all, the erosion of trust that occurs when a team delivers something nobody needed.

---

## 2. The solution trap

Before describing how this phase is executed, we need to talk about an invisible force that sabotages most discovery processes: the unstoppable urge to jump to solutions.

It's an almost physiological mechanism. The human brain isn't designed to sustain the discomfort of an open problem. When we hear a problem, our mind starts generating solutions automatically, often before the other person has finished speaking. In a professional context, this urgency is amplified by deadline pressure, the culture of fast execution, and the belief that value is measured by what you produce, not by what you understand.

This urgency is the solution trap. And it's the number one enemy of good discovery.

The trap works like this: someone describes a symptom ("our team wastes too much time searching for information"), your mind instantly constructs a solution ("they need an internal AI-powered search engine"), and from that moment on, everything you hear is filtered through that solution. Interviews become validation. Questions are oriented to confirm. Data that doesn't fit is discarded. It's not bad faith. It's the normal functioning of a brain seeking certainty in an environment of ambiguity.

**The antidote is not trying not to think about solutions.** That's impossible. The antidote is making the solution your mind generated explicit — writing it down, putting it on paper, hanging it on the wall — and then doing the deliberate work of seeking evidence that contradicts it. Not that confirms it. That contradicts it.

:::danger Anti-pattern: The Solution Trap in Action
**The scene:** In a kickoff meeting, the operations director says: "We need an AI tool to automate monthly reports. Our team loses an entire week each month preparing them."

**What the team hears:** "We need to build an AI report generator."

**What a rigorous discovery uncovers:** The team doesn't lose a week preparing reports. They lose three days collecting data from seven different systems that don't talk to each other, and two days formatting that data into the template that management requires. The problem isn't report generation. It's data fragmentation and an inherited format that nobody has questioned in five years.

**The solution changes completely** when the problem is defined correctly.
:::

---

## 3. What Problem Discovery is and what it isn't

Most failures in this phase don't come from doing it poorly, but from confusing it with something else.

### What it IS

- **An active investigation.** The team goes out to seek information it doesn't have. It talks to real people. Observes real behaviors. Collects data that challenges its prior assumptions.
- **A listening process, not a presentation.** The team comes to learn, not to share what it already knows. The ratio of talking to listening should be, at minimum, 20/80.
- **An exercise in precision.** The result is not a list of problems or a generic pain map. It's a single problem definition — concise, validated, and shared.
- **A collaborative effort.** One person doesn't do it. The team does. The synthesis is built together, not in an office.
- **A commitment to truth.** If the data contradicts the hypothesis you brought in, the data wins. Always.

### What it is NOT

- **It's not a kickoff meeting.** A kickoff is an administrative act. Discovery is an act of thinking.
- **It's not a client briefing.** The briefing is what the client thinks they need. Discovery is what they actually need. Often these are very different things.
- **It's not a validation process.** If you enter discovery with the answer and seek confirmation, you're not doing discovery. You're doing organized bias.
- **It's not a Design Thinking workshop.** Workshops are a possible tool within discovery, but discovery is not reducible to a workshop. It's a process that takes days or weeks, not hours.
- **It's not optional.** In this methodology, skipping discovery isn't going faster. It's building blind.

:::danger Anti-pattern: Decorative Discovery
The team conducts two interviews, confirms what it already believed, and writes a Problem Statement that appeared to be drafted before talking to anyone. The interviews were used as decoration, not as a source of truth.

**How to detect it:** If the final Problem Statement is identical to the starting hypothesis, something went wrong. A discovery that doesn't change anything you believed going in probably wasn't a discovery.
:::

---

## 4. The cognitive biases that sabotage discovery

No team enters discovery with a blank mind. We all carry an invisible baggage of biases that distort what we see, what we ask, and what we interpret. Ignoring these biases doesn't eliminate them. It makes them more dangerous. The only defense is to know them, make them explicit, and design the process to actively counteract them.

These are the most common biases in Problem Discovery and the antidotes we apply:

### Confirmation bias

**What it is:** The tendency to seek, interpret, and remember information that confirms what we already believe. It's the most powerful bias and the hardest to counteract because it operates unconsciously.

**How it appears in discovery:** The team selects interviewees who will confirm their hypothesis. Questions are formulated to get the expected answer. Contradictory data is discarded as "exceptions" or "edge cases."

:::tip Antidote — The Inverted Hypothesis
Before each interview, the team explicitly writes the opposite hypothesis to what it believes. If you believe "users need more data," formulate "users have too much data and don't know what to do with it." Then design at least two questions that seek evidence for that inverted hypothesis. If you find no contrary evidence in 5 interviews, it's a legitimate finding. If you find some, it's a signal that deserves investigation.
:::

### Anchoring bias

**What it is:** The tendency to give disproportionate weight to the first information we receive. The first interview, the first data point, the first opinion becomes the "anchor" that conditions all subsequent interpretation.

**How it appears in discovery:** The first person interviewed defines the problem narrative. Subsequent interviews are interpreted through the lens of the first. Patterns are "discovered" where the first interviewee suggested them.

:::tip Antidote — Delayed Synthesis
Don't interpret anything until you've completed all interviews. The team takes literal notes during interviews, without drawing conclusions. The synthesis is done afterwards, with all data on the table, not cumulatively. If the first interview says "A" and the third says "B," both carry equal weight in the synthesis.
:::

### Authority bias

**What it is:** The tendency to give more credibility to information coming from people with higher hierarchy or perceived status.

**How it appears in discovery:** If a director says the problem is X, the team treats that opinion as fact. Frontline users who contradict the director are "the ones who don't see the full picture." The Problem Statement ends up reflecting the perspective of whoever has the most power, not whoever knows the most about the problem.

:::tip Antidote — Anonymized findings
During synthesis, findings are placed on the Synthesis Board without attribution. It doesn't matter who said what. What matters is what was said and how many times it appears from independent sources. A pattern emerging from three frontline users is stronger than a single executive's assertion.
:::

### Availability bias

**What it is:** The tendency to give more importance to information we remember easily, typically because it's recent, emotional, or vivid.

**How it appears in discovery:** The most emotional interview or the most dramatic story dominates the synthesis, even though it represents an extreme case. The problem gets defined around the most memorable experience, not the most representative one.

:::tip Antidote — Frequency before intensity
When analyzing findings, the team starts with frequency ("how many people mentioned this?") before intensity ("how much pain did this person express?"). A moderate problem that affects all interviewees is more significant than a severe problem that affects only one.
:::

### Framing effect

**What it is:** The way information is presented changes how we interpret it. The same fact, expressed differently, produces different conclusions.

**How it appears in discovery:** How the research question is framed conditions what is found. "Why does our inventory system fail?" and "How do managers handle inventory information?" are questions about the same topic that produce radically different findings. The first presupposes a failure. The second explores a reality.

:::tip Antidote — Triple reframing
Before starting discovery, the team formulates the research question in three different ways with different frames: one from the symptom, one from the behavior, and one from the impact. All three are used during interviews to prevent any single frame from conditioning the findings.
:::

---

## 5. Who participates — and a map almost nobody makes

The composition of the discovery team is not a logistical detail. It's a design decision that determines the quality of what you'll discover. Including the wrong people produces the wrong findings. Excluding the right people produces blind spots you'll pay for later.

### Essential participants

| Participant | Why they participate |
|---|---|
| **Product or solution team** | The people who will be responsible for turning findings into action. They cannot delegate this phase because they need first-hand understanding. A discovery mediated through a summary loses critical nuances. |
| **Direct clients or users** | The people who live the problem. Not executives who talk about the problem, not managers who report on it. The people whose daily reality is affected. Minimum five different people to avoid sample bias. |
| **Stakeholders with direct contact** | People who, while they don't live the problem, observe it closely: customer service, support, field sales, operations. They provide complementary perspective based on real contact. |

### Who does NOT participate

This is the most important rule and the hardest to enforce: **in this phase, no one participates whose only relationship with the problem is organizational or hierarchical.**

This means a director who has never spoken with a user doesn't sit in on interviews. A VP who sponsors the project but doesn't know the details of the problem doesn't influence the synthesis. Their participation will come in Phase 2, Solution Alignment, where their organizational perspective is valuable. Here, their presence distorts the conversation, introduces authority bias, and frequently shortens interviews because their mere presence changes what people are willing to say.

### The Actor Map

There's an exercise that almost no team does and that radically changes the quality of discovery: explicitly mapping all the actors surrounding the problem before starting interviews.

Not just those who live the problem. Everyone who touches it: those who cause it, those who suffer it as an indirect consequence, those who tried to solve it before, those who benefit from it not being solved (yes, they exist), those who will make the final decision about the solution, and those who will implement it. Each of these actors has a distinct and potentially contradictory perspective on the same problem.

The Actor Map is built at the kick-off and answers these questions:

| Question | What it reveals |
|---|---|
| **Who lives the problem daily?** | The primary informants: the people whose experience is the source of truth. |
| **Who decides whether the problem gets solved?** | The decision owner. Their success criteria may differ from the user's. Understanding what they consider "resolved" is critical. |
| **Who will be affected by the solution?** | Indirect actors who can block or boost adoption. A change that solves a problem for some may create another for others. |
| **Who has tried to solve this before?** | Source of learning about what doesn't work and why. Frequently, also a source of resistance if the new solution implies their attempt was a failure. |
| **Who has relevant information we're not seeing?** | The team's blind spots. There's almost always someone who knows something crucial and nobody has asked them. |

This map doesn't replace interviews. It enriches them. It ensures you're not only talking to the most obvious actors and that the Problem Statement reflects the real complexity of the human relationships surrounding the problem.

:::tip Principle 02: The client doesn't know what they want
**The client doesn't know what they want, but they know what they feel.** Don't ask the client what solution they need. Ask them what hurts, what slows them down, what costs them. The solution is your job. The problem is theirs. Respect that division.
:::

---

## 6. The questions that must be answered

Problem Discovery is structured around six fundamental questions. They're not a questionnaire to fill out — they're directions of investigation. Each one opens a different angle on the problem, and together they compose a picture complete enough to produce a quality Problem Statement.

### 6.1 What is the real problem, not the symptom?

This is the most important question and the hardest one. What you're told first is almost always a symptom. "We need a dashboard" is a symptom. "We have no visibility into inventory and lose sales when we run out of stock" is the problem. The difference seems subtle but it determines the entire solution.

There's a distinction that helps: the symptom is what you see. The problem is the gap between reality and what should be happening. "The team takes a week to do reports" is a symptom. The gap is: "Business decisions are made with a week's delay on real data, and by that time the situation has already changed."

:::info Technique
Repeatedly ask "and why is that a problem?" Use the 5 Whys technique. Don't stop at the first answer. When the person says "because it's always been like that" or "because the system doesn't allow it," you're close to the root cause.
:::

### 6.2 Who does it affect and how do they experience it?

A problem doesn't exist in the abstract. It exists in the experience of specific people. You need to understand who lives it, how they experience it in their daily routine, what emotions it generates, and how it impacts their work or life.

But there's a nuance that many teams overlook: not all affected people experience it the same way, and not all matter equally for the problem definition. The store manager who loses sales due to stockouts lives the problem one way. The warehouse manager who receives constant complaints lives it another. The customer who finds an empty shelf lives it a third. The Problem Statement needs to integrate these perspectives, not choose one and discard the rest.

:::info Technique
Ask for concrete stories: "Tell me about the last time this happened to you. What did you do? How did you feel?" Stories contain details that generic answers don't reveal. Emotions are data. A user who says "it makes me angry" is giving you information about the problem's intensity that no metric captures.
:::

### 6.3 What causes it?

Understanding the causes is critical to avoid solving a symptom. Causes can be multiple, interconnected, and operate at different levels: personal, process, system, organizational.

:::info Technique
Map causes in layers. Distinguish between root causes and contributing causes. An Ishikawa diagram or causal map can help visualize the structure of the problem. The root cause is the one that, if eliminated, makes the problem disappear. Contributing causes are those that aggravate it but don't generate it.
:::

### 6.4 What has already been tried and why didn't it work?

This question is a gold mine of information. Previous failed attempts tell you what doesn't work, what constraints exist, and frequently, what part of the problem the user already understands better than you.

:::info Technique
Don't judge previous attempts. Explore what part worked, what part didn't, and why. Partial solutions often contain the seed of the real solution. Ask: "What workaround have you created? What part of that workaround works well?" Those answers reveal invisible constraints that no technical analysis would show.
:::

### 6.5 What is the cost of not solving it?

The cost of the problem is what justifies solving it. If you can't quantify — in time, money, lost opportunity, emotional wear, or risk — the impact of not solving the problem, you don't have a business case. You have a hypothesis.

But there's a point here that many teams avoid because it's uncomfortable: **the cost of not solving the problem is also the most honest criterion for deciding whether it's worth solving.** Not all problems justify a solution. A rigorous discovery can legitimately conclude that the problem exists but its cost doesn't justify the investment. That's not a discovery failure. It's its most valuable outcome: avoiding building something that doesn't make economic sense.

:::info Technique
Quantify whenever possible. "It costs me 3 hours per week" is better than "it costs me a lot of time." Concrete numbers anchor the conversation and facilitate subsequent prioritization. When direct quantification isn't possible, use proxies: "How many times per month does it happen? How much time do you lose each time? How many people are affected?"
:::

### 6.6 When does it occur, how often, in what context?

The temporal and situational context of the problem reveals patterns that don't appear in a static description. A problem that occurs every day is different from one that occurs once a month. A problem that appears only under pressure suggests different causes than one that is constant.

:::info Technique
Look for triggers and conditions. "When does this problem appear? Are there days or moments when it's worse? Is there something that triggers it?" Contextual patterns frequently reveal the root cause more effectively than direct questions about causes.
:::

---

## 7. The step-by-step process

Problem Discovery is not a free-form activity. It's a structured process with four clear steps, each with a specific purpose and a partial deliverable that feeds the next. Discipline in the sequence is what differentiates a rigorous discovery from a well-intentioned conversation.

### Step 1. Discovery Kick-off

*Estimated duration: 1 session of 2-3 hours*

The kick-off is not the discovery. It's the preparation for discovery. Its purpose is fourfold: align the team on the scope of the investigation, identify the people to be interviewed, make explicit the starting hypotheses the team brings with them, and build the Actor Map.

This last point is crucial. Every team arrives at discovery with prior hypotheses about the problem. Pretending they don't exist is counterproductive. The right thing to do is make them explicit, write them down, and hang them on the wall. Not to validate them, but so the team is aware of its biases and can actively challenge them during interviews.

#### Kick-off activities

1. **Define the scope of the investigation:** what area of the problem we will explore and, with equal precision, what is out of scope.
2. **Build the Actor Map:** who lives the problem, who decides, who is affected, who has tried to solve it, who has information we're not seeing.
3. **Identify interviewees:** minimum 5, selected from the Actor Map with diversity of roles and perspectives.
4. **Document starting hypotheses:** what the team believes it knows about the problem. Also write the inverted hypothesis for each one.
5. **Identify known constraints:** budget, time, regulations, technical limitations, organizational politics. Not to solve anything, but to know what conditions the future solution space.
6. **Design the Interview Guide:** the question guide that will structure the interviews, including at least one question designed to challenge the main hypothesis.
7. **Assign roles:** who interviews, who takes notes, who coordinates logistics.

:::note Practical example: Kick-off for an inventory management project
**Starting hypothesis:** "Store managers need a dashboard to see inventory in real time."

**Inverted hypothesis:** "Managers already have the information they need but don't trust it" or "The problem isn't the information but the replenishment process."

**Actor Map:**
- *Live the problem:* Store managers (3 regions), warehouse managers.
- *Decide:* Retail operations director.
- *Indirectly affected:* Purchasing team (receiving orders based on outdated data), end customers.
- *Tried to solve it:* The IT team implemented an alert system a year ago. It didn't work. Why?
- *Know something we don't see:* The customer service team, which receives daily complaints about stock.

**Known constraints:** Legacy ERP with daily batch updates, limited integration budget, minimum stock regulations for health and food products.

**Scope:** Explore the inventory visibility problem. Out of scope: transportation logistics.
:::

### Step 2. In-depth interviews

*Estimated duration: 45-60 minutes per interview × minimum 5 interviews*

Interviews are the heart of discovery. They are structured but not rigid conversations, designed to extract the real experience of the people who live the problem. They are not surveys. They are not questionnaires. They are conversations with a clear direction and enough flexibility to follow unexpected threads when they appear.

#### The Interview Guide

The interview guide is not a script. It's a structure that ensures all interviews cover the six fundamental questions while leaving room for exploration. It's organized in four blocks:

| Block | Purpose | Sample questions |
|---|---|---|
| **Opening** (5-10 min) | Establish trust and context. It's not small talk: it's understanding the person's role, their relationship with the problem, and their willingness to share. | *"Tell me about your day-to-day. What's your main responsibility? How does it relate to [the problem area]?"* |
| **Problem exploration** (20-30 min) | The central block. This is where the six fundamental questions are answered. Follow the person's thread, not the guide's order. | *"Tell me about the last time you faced this. What happened? And why is that a problem? What have you tried to solve it?"* |
| **Depth** (10-15 min) | Follow the most interesting threads. Ask for specific examples. Quantify impacts. Search for the emotions behind the answers. | *"Can you give me a specific example? How many times does it happen per month? What do you feel when it occurs? What would you do if this were solved tomorrow?"* |
| **Close** (5 min) | Give space for the unasked. Frequently, the most valuable insight emerges here, when the person relaxes and adds something they didn't know how to say before. | *"Is there anything I haven't asked you that you think I should know? Anything else you'd like to add about this topic?"* |

#### Golden rules of interviewing

1. **Never ask closed or leading questions.** "Do you think inventory is a problem?" is not a question. It's a suggestion in disguise. Ask open-ended: "What's the hardest part of your day-to-day?"
2. **Never propose solutions during the interview.** Your job is to understand, not to solve. If you propose a solution, the person will stop thinking about the problem and start evaluating your idea.
3. **Follow unexpected threads.** If the person mentions something not in your guide but seems relevant, follow that thread. The best findings are usually off-script.
4. **Seek stories, not opinions.** "Tell me about the last time..." produces much richer information than "What do you think about...?"
5. **Respect silences.** When the person goes quiet, don't fill the space. They're thinking. What comes after the silence is usually the most honest.
6. **Always go in pairs: one interviews, one takes notes.** Never interview alone. The note-taker captures what the interviewer can't see while conversing.

:::danger Anti-pattern: Trap Questions
*"Don't you think it would be useful to have a dashboard showing you inventory in real time?"*

This question contains the solution, suggests the answer, and makes it difficult for the person to say no. It's the equivalent of asking "wouldn't you like your life to be better?" The answer is always yes, and the information you get is zero.

**The correct version:** "Tell me how you know today how much stock you have of each product. What do you do when you need that information?"
:::

### Step 3. Findings synthesis

*Estimated duration: 1-2 sessions of 3-4 hours with the full team*

Synthesis is the moment when collected information becomes knowledge. The team meets with all notes, transcripts, and impressions from the interviews and works together to identify patterns, tensions, and the real problem emerging from the body of data.

This phase is hard. There's contradictory information. There are findings that don't fit with prior hypotheses. There are moments of frustration when it seems like each interviewee lives a different problem. That's normal. The real problem usually appears when you find the patterns that connect the differences, not those that ignore them.

#### The Synthesis Board

The Synthesis Board is the central artifact of this phase. It's a visual map where the team places individual findings and groups them by patterns. It can be done on a physical whiteboard, in Miro, FigJam, or any tool that allows collaborative visual manipulation. What matters is not the tool but three principles:

1. **It's built together.** One person doesn't do it and present it to the rest. Everyone participates in placing findings and discussing groupings.
2. **Start with data, not categories.** First place the individual findings. Then look for patterns. If you start with categories, you fall into confirmation bias.
3. **Outliers are respected.** A finding that doesn't fit any pattern is not discarded. It's placed aside and kept visible. Sometimes the outlier is the most important signal.

#### Synthesis techniques

| Technique | What it does | When to use it | Watch out for |
|---|---|---|---|
| **Affinity map** | Group findings by thematic similarity. | Inductive discovery when there's lots of diverse data. | *Works poorly when the team groups by pre-existing categories instead of letting patterns emerge.* |
| **Jobs To Be Done** | Identify the "job" the user is trying to do and where it fails. | Problems where the person has a clear goal but can't reach it. | *Requires understanding of the functional, social, and emotional context of the "job".* |
| **Empathy map** | Organize what the person says, thinks, does, and feels. | Capturing the emotional dimension of the problem. | *Useful as a complement, not as a primary synthesis technique.* |
| **5 Whys analysis** | Reach the root cause by repeatedly asking "why." | When symptoms are clear but causes aren't. | *Don't force exactly 5 levels. The goal is the root cause, not the number.* |
| **Contextual observation** | Observe the user in their real environment while they do their work. | When the problem is process-related and interviews don't capture it well. | *Consumes more time but reveals behaviors that interviews don't show.* |

#### The synthesis question

At the end of synthesis, the team must be able to answer a single question: **"What is the real problem these people live, expressed so that anyone in the organization would understand it the same way?"**

If you can't answer this question with a single clear sentence, the synthesis isn't finished.

### Step 4. Drafting and validating the Problem Statement

*Estimated duration: 1-2 days of drafting + 2-3 days of validation*

The Problem Statement is the final deliverable of this phase and one of the most important documents in the entire methodology. It's not a summary of the discovery. It's a distillation: the clearest, most concise, and most precise expression of the real problem the team has discovered.

---

## 8. The anatomy of a complete Problem Statement

The Problem Statement doesn't exceed half a page. That constraint is deliberate. Brevity forces precision. A long Problem Statement is a Problem Statement that hasn't finished being thought through.

But brevity is not simplicity. A good Problem Statement is a dense document that integrates multiple dimensions of the problem into a reduced space. To achieve this, we've identified seven elements that, when present, produce a problem definition that is complete, actionable, and resistant to ambiguity.

### The seven elements of a Problem Statement

| # | Element | What it describes | Key question | Example |
|---|---|---|---|---|
| 1 | **The gap** | The distance between what happens and what should happen. Not the symptom, but the real gap. | *What is wrong? What's the difference between the current and desired situation?* | *"Managers discover stockouts when the customer asks, not before."* |
| 2 | **The owner** | Who lives the problem and who has the ability to decide it gets solved. Sometimes they're the same person; often they're not. | *Who suffers the consequences? Who can authorize the solution?* | *"Store managers live it. The operations director decides."* |
| 3 | **The success criteria** | What the world will look like when the problem is solved. Not in terms of solution, but of observable and measurable outcome. | *How will we know the problem was solved?* | *"Managers anticipate stockouts at least 24h before they occur."* |
| 4 | **The constraints** | The real barriers that limit the solution space: budget, time, regulations, legacy technology, organizational politics. | *What can't we change? What limits what's possible?* | *"ERP updates in daily batch; replacement not viable in 12 months."* |
| 5 | **The actors** | All stakeholders who can influence the solution or be affected by it, beyond whoever lives the problem directly. | *Who can block, boost, or be impacted?* | *"Purchasing, warehouse, IT, customer service, suppliers."* |
| 6 | **The temporal context** | When it happens, how often, and what temporal patterns the problem has. | *When does it appear? Is it constant or does it have triggers?* | *"Daily in peak season; weekly in off-season."* |
| 7 | **The cost of inaction** | The quantified impact of not solving the problem, expressed in terms the decision owner understands. | *What is lost every day/week/month this isn't solved?* | *"12% of sales lost + 45 min/day × 120 stores."* |

The first three elements — the gap, the owner, and the success criteria — are the heart of the Problem Statement. Without them, you don't have a problem definition; you have a vague description of discomfort. The remaining four — constraints, actors, temporal context, and cost of inaction — are what turn that definition into something actionable, complete, and resistant to interpretation.

:::tip Insight
**Why is the success criteria defined here and not in the solution phase?** Because the success criteria belongs to the problem, not the solution. If you don't define what "solved" looks like before thinking about solutions, each stakeholder will have a different definition and you won't discover it until it's too late. Defining success here is an act of preventive alignment that saves enormous conflicts later.
:::

### Complete Problem Statement example

:::note Problem Statement: Inventory Visibility in Retail
**The gap:** The chain's store managers (120 points of sale) discover stockouts when a customer asks for a product that isn't available, not before. The central inventory system updates every 24 hours, which means all replenishment decisions are based on the previous day's data.

**Who lives it / Who decides:** Store managers live it daily, responsible for 40-80 SKUs per point of sale. The investment decision for a solution belongs to the retail operations director.

**Success criteria:** Managers can anticipate a stockout at least 24 hours before it occurs and act preventively. The "discovered by customer" rate drops from the current 100% to less than 15%.

**Context:** Occurs daily during peak season, when the rotation speed of some SKUs exceeds the system's update frequency. In off-season, frequency drops to weekly. Managers have developed manual workarounds — personal spreadsheets, calls to the warehouse, physical counts — consuming an average of 45 minutes daily and unreliable.

**Constraints:** The central ERP (SAP) updates in daily batch and its replacement is not planned for the next 18 months. Integration budget limited to €150K. Minimum stock regulations for health and food products.

**Key actors:** Purchasing team (replenishment decisions based on outdated data), warehouse managers (receiving orders that don't reflect real demand), IT team (maintains integrations), customer service (handles customer complaints about out-of-stock), frequent replenishment suppliers.

**Cost of inaction:** 12% of sales lost due to lack of available stock at the moment of demand. 45 minutes daily of manual work per manager × 120 stores = 90 hours/day of lost productivity. Erosion of customer trust from recurring "not available" experiences.
:::

### Validation: two levels almost nobody completes

A Problem Statement is not complete until it has been validated. But validation has two levels that most teams don't distinguish.

**Level 1 — Validation with those who live the problem.** The Problem Statement is presented to at least two of the clients or users interviewed. The question is direct: "We've written this as a summary of what we understand the problem to be. Do you recognize it? Is anything missing? Is anything incorrect?" If the person reads it and says "yes, this is exactly what happens," the gap and context are validated. If they say "well, more or less, but it's missing..." you need to iterate. No exceptions.

**Level 2 — Validation with the decision owner.** The user who lives the problem validates the gap and context. The decision owner validates the success criteria, constraints, and cost of inaction. Both validations are necessary. If the user recognizes the problem but the decision-maker doesn't recognize its cost, there will be no solution. If the decision-maker recognizes the cost but the user doesn't recognize the gap, the solution won't solve the right thing.

:::danger Anti-pattern: The Narcissistic Problem Statement
A Problem Statement that uses internal organizational language, technical jargon, or abstract concepts that the user doesn't recognize. If you read your Problem Statement to the person who lives the problem and need to explain what it means, it's poorly written.

**The test:** Would a person external to the organization, with no prior context, understand the problem by reading this document? If the answer is no, simplify.
:::

---

## 9. The artifacts of this phase

Each phase of the Problem-Driven AI methodology produces specific artifacts. They are not optional. They are the evidence that the work was done rigorously and the memory that feeds everything that follows. In Problem Discovery, the artifacts are four:

| Artifact | When it's created | What it contains | Why it matters |
|---|---|---|---|
| **Actor Map** | Built at the kick-off, before selecting interviewees. | Visual map of all actors surrounding the problem: who lives it, who decides, who is affected, who has tried to solve it, who has hidden information. | Ensures discovery isn't limited to the most obvious perspective. Prevents the Invisible Stakeholder anti-pattern. |
| **Interview Guide** | Created at the kick-off, after the Actor Map. | Open question guide, without leading questions. Includes interviewee context, opening, exploration, depth, and closing blocks. Includes at least one question that challenges the main hypothesis. | Ensures consistency across interviews without sacrificing flexibility. Allows different team members to interview at the same quality level. |
| **Synthesis Board** | Built after interviews, in the synthesis session. | Visual map of findings grouped by patterns. Includes anonymized individual findings, affinity groupings, identified tensions, outliers, confirmed and refuted hypotheses. | It's the memory of the team's thinking process. Allows returning to the data at any point and reconstructing the reasoning that led to the Problem Statement. |
| **Problem Statement** | Drafted after synthesis and validated at two levels. | Problem definition of no more than half a page with seven elements: gap, owner, success criteria, constraints, actors, temporal context, and cost of inaction. | It's the input deliverable for Phase 2 (Solution Alignment). If this document isn't precise, everything that follows is contaminated. |

---

## 10. Exit Criteria: the Gate Review

Problem Discovery is not complete when the team feels it understands the problem. It's complete when simultaneous and verifiable conditions are met:

:::caution Gate 1 → 2: Passage conditions
- ✅ The Problem Statement has been validated directly with at least two of the clients or users interviewed and they recognize it as a faithful description of their reality.
- ✅ The success criteria has been validated with the decision owner and they recognize it as the definition of "solved."
- ✅ Documented constraints have been verified with the actors who impose them (IT for technical constraints, legal for regulatory, finance for budgetary).
- ✅ There is explicit agreement within the team on the Problem Statement's formulation. Not majority. Not silence interpreted as agreement. Real agreement.
- ✅ The Actor Map, Interview Guide, Synthesis Board, and Problem Statement are documented and accessible.
- ✅ Starting hypotheses have been explicitly confirmed or refuted.
- ❌ Do not advance if the Problem Statement hasn't been externally validated, even if the team is convinced it's correct.
- ❌ Do not advance if there are relevant disagreements within the team that haven't been resolved.
- ❌ Do not advance if the success criteria isn't defined or if different stakeholders have incompatible criteria that haven't been resolved.
:::

These exit criteria exist to protect the team from itself. The pressure to move forward is real. Deadlines are real. The temptation to accept a Problem Statement without externally validating it is enormous. But every shortcut here is paid for many times over in subsequent phases.

---

## 11. Anti-patterns: what can go wrong

Over years of practice, we've identified recurring failure patterns in Problem Discovery. Knowing them doesn't guarantee avoiding them, but it significantly increases the probability of detecting them in time.

:::danger Anti-pattern: Organized Bias
**What it is:** The team enters discovery with a firm hypothesis and designs interviews, consciously or unconsciously, to confirm it. Questions are closed, interviewees are selected because they'll confirm the thesis, and data that contradicts it is discarded as exceptions.

**How to detect it:** The final Problem Statement is identical to the starting hypothesis documented at the kick-off. No interview changed anything the team believed at the start.

**How to prevent it:** Document hypotheses before discovery. Include at least one question in each interview that explicitly seeks to challenge the main hypothesis. Assign someone on the team the role of "devil's advocate" during synthesis.
:::

:::danger Anti-pattern: Express Discovery
**What it is:** The team conducts 1-2 interviews, quickly confirms what it believed, and declares discovery complete in less than a week. The pressure to move forward wins over the need to go deeper.

**How to detect it:** Fewer than 5 interviews conducted. The Synthesis Board has few notes and "obvious" patterns. There are no outliers or tensions.

**How to prevent it:** Establish the minimum of 5 interviews as a non-negotiable rule. If after 5 interviews there are no tensions or surprises, the questions probably weren't the right ones.
:::

:::danger Anti-pattern: Problem Statement by Committee
**What it is:** The Problem Statement is drafted in a meeting with too many people, diluted so everyone agrees, and ends up so generic it says nothing concrete. It's the result of optimizing for political consensus instead of precision.

**How to detect it:** The Problem Statement contains phrases like "need to improve operational efficiency" or "optimize the user experience." If you could paste that Problem Statement into any project at any company and it would still sound plausible, it's too generic.

**How to prevent it:** One person drafts, the team reviews. Don't draft as a group. The specificity test: Is this Problem Statement only true for this specific problem? If the answer is no, be more precise.
:::

:::danger Anti-pattern: The Invisible Stakeholder
**What it is:** Direct users are interviewed but people who observe the problem from a different perspective are ignored: support, field sales, operations. The result is a correct but incomplete Problem Statement.

**How to detect it:** The Problem Statement only reflects one perspective. There's no tension between different views of the problem. The Actor Map has empty roles.

**How to prevent it:** Review the Actor Map and verify that at least one interviewee represents each relevant actor cluster.
:::

:::danger Anti-pattern: The Solution Disguised as a Problem
**What it is:** The Problem Statement describes an absence of a solution instead of a real problem. "We don't have an inventory dashboard" is not a problem. "We lose sales because we don't know when a product runs out until the customer asks for it" is.

**How to detect it:** If the Problem Statement contains the word "we need" followed by a tool or functionality, it's a solution in disguise.

**How to prevent it:** Apply the multiple-solution test: if the problem is well-defined, it should be possible to imagine at least three different solutions. If it only admits one, you're probably describing the solution, not the problem.
:::

:::danger Anti-pattern: Undefined Success
**What it is:** The Problem Statement perfectly describes the gap and its cost, but doesn't say what "solved" will look like. Each stakeholder assumes a different definition of success. The team builds the solution, delivers it, and three different people say it's not what they expected — each for a different reason.

**How to detect it:** There's no explicit success criteria in the Problem Statement. Or there is one so vague it admits multiple interpretations: "improve inventory visibility" without defining what "improve" means or how it will be measured.

**How to prevent it:** Before closing the Problem Statement, ask each key stakeholder: "If we solve this perfectly, how will you know? What will be different that you can observe or measure?" If the answers diverge, alignment is needed before moving forward.
:::

:::danger Anti-pattern: Phantom Constraints
**What it is:** The team assumes constraints that don't exist ("the system doesn't allow that") or ignores constraints that do ("surely legal won't have a problem"). Both errors distort the solution space: the first limits it unnecessarily, the second produces unfeasible solutions.

**How to detect it:** Documented constraints haven't been verified with the source. Nobody has asked IT whether the system really doesn't allow it. Nobody has consulted legal.

**How to prevent it:** Every documented constraint needs a source. "According to the IT team, the ERP doesn't support real-time updates" is a verified constraint. "The system doesn't allow it" without a source is an assumption that may be wrong.
:::

---

## 12. Duration and effort

Problem Discovery has no fixed duration because it depends on the complexity of the problem, user accessibility, and the team's prior knowledge level. However, these are typical references:

| Scenario | Duration | What it includes |
|---|---|---|
| **Simple problem, accessible users** | 1-2 weeks | 5 interviews + 1 synthesis session + 1 validation round. |
| **Medium complexity problem** | 2-3 weeks | 5-8 interviews + contextual observation + 2 synthesis sessions + iterated validation. |
| **Complex problem, multiple stakeholders** | 3-5 weeks | 8-12 interviews with different profiles + quantitative analysis + extended synthesis + validation with multiple groups + constraint verification. |

**General rule:** if you're dedicating less than 15% of the project's total time to Problem Discovery, you're probably investing too little. If you're dedicating more than 30%, you're probably over-analyzing. The sweet spot is between 15% and 25% of total time.

---

## 13. Connection to Phase 2: Solution Alignment

The Problem Statement is the input document for the next phase. When the team has completed the Gate Review and the Problem Statement is validated, something important happens: the team earns the right to think about solutions.

This concept — earning the right to build — is central to the methodology. It's not a matter of permission or bureaucracy. It's a matter of quality. A team that has done rigorous discovery arrives at the solution phase with an understanding of the problem that allows them to evaluate solutions with judgment. A team that skipped discovery arrives at the solution phase with opinions, not judgment. And opinions, when not backed by data, produce endless discussions.

The Problem Statement travels to Phase 2 accompanied by the Actor Map, the Synthesis Board, and the Interview Guide. These four artifacts together contain **the defined problem, the people surrounding it, the evidence that supports it, and the method by which it was discovered.** They are the foundation upon which the solution will be built.

And there's one element that deserves special attention in that transition: the success criteria defined in the Problem Statement becomes the evaluation criteria for the solution in Phase 2. It's not the solution that defines its own success. It's the problem that defines it. This distinction seems subtle but prevents one of the most costly errors: building something that works perfectly by its own metrics but doesn't solve what it was supposed to solve.

:::tip Principle 05: Building is a symptom
**Building is a symptom, not a goal.** Building is the natural consequence of having thought well. It's not an achievement in itself. A team that celebrates having built fast without validating the problem is celebrating in the wrong direction.
:::

---

*The problem is still the product.*
*AI just changed what happens after you find it.*
