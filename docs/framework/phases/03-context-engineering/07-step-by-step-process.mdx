---
title: "The step-by-step process"
sidebar_label: "Step by Step"
slug: /framework/phases/context-engineering/step-by-step-process
description: "A structured process with five steps: establish Rules, design the Agent chain, generate strategic documents, decompose into Skills, and validate through outputs."
sidebar_position: 1
tags: [phases, context-engineering, process, agents, rules, skills]
---

# The step-by-step process

Context Engineering is not a creative writing exercise. It's a structured translation process that converts the human understanding captured in Phases 1 and 2 into a system that AI can process faithfully. Every step has a clear purpose, a concrete deliverable, and a validation criterion.

## Step 1. Establish Rules (project-context.md)

*Estimated duration: 1-2 days*

Rules come first because everything depends on them. An Agent without Rules improvises. A Skill without Rules produces unpredictable results. The project-context.md is the constitution that every Agent loads before executing any Skill — not as a reference to consult, but as a constraint that restricts.

### Where to start

Take the Solution Brief from Phase 2 and extract every decision that applies globally. Constraints become Rules. Technology choices become Rules. Conventions become Rules. The Solution Brief contains these decisions implicitly — your job is to make them explicit and unambiguous.

Think of it like writing a company employee handbook. New hires don't have years of institutional knowledge. They need everything written down: what tools to use, what's prohibited, how to escalate problems. AI Agents are perpetual new hires — they only know what's in the handbook.

### What the project-context.md must contain

| Section | What it includes | Why it matters |
|---|---|---|
| **Tech stack** | Languages, frameworks, versions. | An Agent that doesn't know the stack might write Python when the project uses TypeScript. |
| **Code conventions** | Naming, file structure, mandatory patterns. | Without explicit conventions, two Agents produce inconsistent code — both correct individually, incoherent together. |
| **Security constraints** | What's prohibited, what requires escalation. | A single security violation can compromise the entire project. These are always Level 5 Rules. |
| **Integration rules** | How components communicate (REST, gRPC, events). | When a Skill involves integration, these Rules define the how. |
| **Agent limits** | What each Agent can decide autonomously and what requires escalation. | Prevents Agents from making decisions outside their role — like a developer deciding to change the database without consulting the architect. |
| **Gap protocol** | "When an Agent detects insufficient information in a Skill, it signals the gap. It does not fill it." | Without this, Agents invent answers with total confidence, creating invisible context debt. This is the single most important Rule. |
| **Justified global decisions** | Each cross-cutting decision with its "why." | If an Agent understands *why* a Rule exists, it can apply it correctly in situations the Context Engineer didn't foresee. |

### Calibrate precision levels

Not all Rules need the same rigidity. The key is to calibrate: invest precision where the impact on Agents and Skills is high, and delegate where it's low.

| Level | Type | What it means for Agents and Skills | Example |
|---|---|---|---|
| **5** | Prescriptive | Absolute restriction. No Agent can violate it in any Skill. If a Skill contradicts it, the Agent must escalate. | "All endpoints return JSON &#123; data, error, meta &#125;. No exceptions." |
| **4** | Specific | Every Skill touching this area must comply. Agents apply it without interpretation. | "Push alert to manager in under 2 minutes when stock falls below threshold." |
| **3** | Directed | Agents follow the direction. Skills can adapt it to their specific context. | "Informative tone, no jargon. Adaptable by audience." |
| **2** | Orientative | Preference, not mandate. Agents consider it; Skills may deviate if justified. | "We prefer tables for inventory data. Other formats acceptable." |
| **1** | Delegated | The Context Engineer explicitly delegates to the Agent. The Skill doesn't prescribe; the Agent decides. | "camelCase for variables. Rest: Agent's judgment." |

Delegating is not forgetting. It's deciding what doesn't need prescription. Levels 1-2 are conscious delegations to the Agent. Levels 4-5 are limits no Agent can cross in any Skill.

:::note Practical example: Calibrating precision for an inventory system
A retail company building an inventory management system:

**Level 5 (Prescriptive):** "All inventory quantities are integers. Never use floating point for stock counts." — A single float can cause rounding errors that cascade across the entire supply chain.

**Level 4 (Specific):** "Low stock alerts fire within 2 minutes of threshold breach." — The business promised this SLA to store managers.

**Level 3 (Directed):** "Error messages are user-friendly, not technical. Adapt language to the audience." — Customer-facing errors differ from admin-facing errors, but both must be clear.

**Level 2 (Orientative):** "We prefer real-time WebSocket updates for dashboards. REST acceptable where WebSocket adds unnecessary complexity." — Performance preference, not a hard constraint.

**Level 1 (Delegated):** "CSS naming convention for UI components: Agent's judgment." — Low-impact decision that doesn't affect system coherence.
:::

### The three-reads test

Before moving to Step 2, apply this validation: an Agent that receives only the project-context.md should be able to answer three questions:

1. **What technologies do I use?** — If the answer isn't there, an Agent might choose the wrong stack.
2. **What can't I do?** — If prohibitions aren't explicit, Agents will make decisions that seem locally reasonable but violate project-wide constraints.
3. **What's the convention for any recurring pattern?** — If naming, formatting, or architectural patterns aren't documented, every Agent will invent their own.

If any answer is missing, the Rules are incomplete.

## Step 2. Design the Agent Chain

*Estimated duration: 1-2 days*

The translation from Solution Brief to complete context system is executed by a chain of specialized Agents. Think of it as an assembly line: each station receives the previous one's work, adds value within strict quality controls, and passes it to the next.

### The standard chain

Most projects use five Agents in sequence. Simpler projects may combine roles; complex ones may add specialists. But the five-Agent chain covers the vast majority of cases:

| Agent | Input | What it does | Output |
|---|---|---|---|
| **Analyst Agent** | Problem Statement + Solution Brief | Translates human artifacts into structured requirements. Does not discover or invent — it reformats. | Structured requirements document |
| **PM Agent** | Structured requirements | Generates the PRD: what to build, for whom, with what priority. Defines use cases. | Complete PRD |
| **Architect Agent** | PRD | Translates PRD into technical decisions. Generates new Rules from architecture decisions. | Architecture Document + new Rules in project-context.md |
| **SM Agent** | PRD + Architecture | Decomposes the solution into self-contained Skills. Each Skill includes all context for its executing Agent. | Story Files (Skills) |
| **QA Agent** | Output of each Agent | Validates fidelity, completeness, consistency with Rules. Checks at every chain link. | Validation report |

### Define each Agent with five elements

Every Agent definition must include five elements. Missing any one creates a gap that will surface during execution:

1. **Identity** — Who it is: role, expertise, perspective. Determines how the Agent interprets Rules and from what angle it approaches Skills.
2. **Responsibilities** — What it does: tasks, expected outputs. Defines what types of Skills it can execute.
3. **Limits** — What it does NOT do. As important as responsibilities. Prevents an Agent from stepping on another's territory.
4. **Rules it applies** — Explicit reference to project-context.md. The Agent knows which Rules to load before executing any Skill.
5. **Gap protocol** — What it does when information is insufficient. The critical Rule: signal the gap, don't invent.

:::note Practical example: Architect Agent definition
**Identity:** Senior technical architect specializing in distributed systems. Thinks in terms of scalability, maintainability, and operational cost.

**Responsibilities:** Translate PRD into technical decisions. Produce the Architecture Document. Generate ADRs (Architecture Decision Records) for each significant decision. Promote cross-cutting technical decisions to Rules in project-context.md.

**Limits:** Does NOT add functional requirements — that's the PM Agent's job. Does NOT modify the PRD. Does NOT create Skills — that's the SM Agent's job. If a functional requirement seems missing, signals it to the PM Agent.

**Rules it applies:** All Rules in project-context.md, with specific focus on tech stack, security constraints, and integration rules.

**Gap protocol:** When the PRD lacks technical detail needed for an architecture decision, document the gap in the Architecture Document as an "open question" and flag it to the Context Engineer. Do not assume the answer.
:::

### Descending fidelity

Each Agent transforms the previous one's output, but never contradicts it, never enriches it with invention, and never reinterprets it. The fidelity Rules ensure the chain doesn't degrade the context.

Think of it like a relay race: each runner carries the same baton. They can run their leg faster or slower, but they can't change what's in the baton. When the SM Agent creates the final Skills, they're faithful to the original Problem Statement because every link in the chain was governed by the same Rules.

## Step 3. Generate Strategic Documents

*Estimated duration: 2-5 days (depends on project complexity)*

Between Rules (global layer) and Skills (execution layer), there's an intermediate layer of documents that define the "what" and "how" at the system level.

### The PRD: what to build and for whom

The PRD is the translation of the Solution Brief into Agent language. Each section will be consumed by specific Agents to produce additional Rules or concrete Skills:

| PRD section | What it contains | Agent that consumes it | What it produces |
|---|---|---|---|
| **Vision and scope** | What it does, what it doesn't, for whom. | Architect + SM Agent | Scope Rules + bounded Skills. |
| **Use cases** | Trigger, flow, expected result. | SM Agent | Each use case generates one or more Skills. |
| **Success criteria** | Measurable KPIs. | QA Agent | Acceptance criteria for validation Skills. |
| **Constraints** | Technical, business, regulatory. | Architect Agent | New Rules in project-context.md. |
| **Active assumptions** | What's taken as true without verification. | All Agents | Risk signals in every affected Skill. |
| **Priorities** | P0, P1, P2. | SM Agent | Skill sequence: P0 first, then P1, then P2. |

:::info Total traceability
Every PRD element has a source in Phase 1 or 2. Every Skill the SM Agent generates traces to the PRD. Every Rule the Architect generates traces to the PRD. The complete chain is: **Problem Statement → Solution Brief → PRD → Rules + Skills.** If a Skill can't be traced back to the Problem Statement, it's invention.
:::

### The Architecture Document: technical decisions that become Rules

The Architecture Document translates the PRD into technical decisions. But its most critical function is this: **architecture decisions become global Rules.** When the Architect Agent decides all services communicate via gRPC, that's not a local decision — it's a new Rule that all Agents must respect in all Skills.

This is why the Architect Agent is the only Agent that updates the project-context.md. Others read it; the Architect writes to it.

The Architecture Document includes:

- **ADRs (Architecture Decision Records):** Each decision with context, alternatives considered, decision made, and consequences. Cross-cutting decisions get promoted to Rules.
- **Data model:** Entities, relationships, format. Development Skills inherit this model via Rules.
- **AI strategy:** Model type, data strategy (RAG, fine-tuning, few-shot), pipeline, governance. Defines specific Rules for Agents and Skills interacting with AI.
- **Non-functional requirements:** Performance, security, observability. Translated into Level 4-5 Rules.

:::note Practical example: Architecture decision becomes a Rule
The Architect Agent decides: "All services communicate via REST with JSON &#123; data, error, meta &#125; envelope. Chosen over GraphQL for simplicity given the team's experience. Consequence: all API Skills must implement this format."

This ADR gets promoted to a **Level 5 Rule** in project-context.md. Now every Agent building any API Skill automatically inherits this constraint. The Rule carries the "why" so that if a future situation isn't covered, the Agent understands the reasoning.
:::

## Step 4. Decompose into Skills

*Estimated duration: 2-5 days*

This is where the SM Agent breaks everything — PRD, Architecture Document, Rules — into concrete tasks that development Agents will execute. Each Skill is a self-contained unit of work, like a work order that contains everything the worker needs.

### The five elements of every Skill

1. **Objective** — What must be achieved. Not how, but what. The Agent uses it to make decisions when facing ambiguities, within the Rules.
2. **Specific context** — Extracts from the PRD and Architecture. Only what *this* Skill needs. Complements global Rules with task-specific information.
3. **Acceptance criteria** — Verifiable conditions, written as assertions. The QA Agent uses these to validate the output.
4. **Dependencies** — Which other Skills must be complete first. Agents don't execute Skills out of sequence.
5. **Specific constraints** — Limitations for this task, additional to global Rules. If there's a conflict between a constraint and a Rule, the Rule wins. Always.

### Three types of Skills

| Type | Granularity | When to use it | Example |
|---|---|---|---|
| **Atomic** | One task, one output. | The task is self-contained and one Agent can complete it in one interaction. | "Create endpoint GET /inventory/&#123;sku&#125;." |
| **Composite** | Multiple coordinated sub-tasks. | Several related sub-tasks share context and should be handled together. | "Alerts module: data model + business logic + notification." |
| **Integration** | Connects outputs of other Skills. | Two or more completed Skills need to work together. Integration Rules from project-context.md are especially critical. | "Integrate inventory with alerts, validate end-to-end flow." |

### The self-containment test

For every Skill, ask: **"Can an Agent that reads only this Skill and the project-context.md complete the task without asking anything?"**

If the answer is no, context is missing. Add it to the Skill — don't assume the Agent already knows it.

:::note Practical example: A well-designed Skill vs. a poorly-designed one
**Poor Skill:** "Build the inventory endpoint."
- Missing: which endpoint? What data? What format? What error handling? The Agent will guess, and its guesses will be confident but potentially wrong.

**Well-designed Skill:**
- **Objective:** Create a REST endpoint that returns the current stock level for a given SKU.
- **Context:** The inventory model uses `sku` (string, unique) and `quantity` (integer). The data model is in the Architecture Document, section 3.2.
- **Acceptance criteria:** Returns 200 with &#123; data: &#123; sku, quantity, warehouse &#125;, error: null, meta: &#123; timestamp &#125; &#125;. Returns 404 for unknown SKU. Response time under 200ms.
- **Dependencies:** Data model Skill (S-003) must be complete.
- **Constraints:** Stock quantities are always integers (Level 5 Rule). OAuth 2.0 authentication required (Level 5 Rule).
:::

## Step 5. Validate through Outputs

*Estimated duration: 1-3 days*

Context isn't validated by reviewing documents. It's validated by running the system and judging the results. A perfect set of Rules, well-defined Agents, and detailed Skills can still produce mediocre outputs if the interaction between the three fails.

### The validation cycle

1. The Context Engineer presents the complete system: Rules (project-context.md), Agents (definitions), Skills (Story Files).
2. Agents process sample Skills and produce outputs: code, designs, decisions.
3. Stakeholders from Phases 1 and 2 review the outputs.
4. The question: **"Is this output recognizable as a faithful expression of the Problem Statement and the Solution Brief?"**
5. If yes: context validated. If no: the Context Engineer adjusts Rules, Agents, or Skills and repeats.

### The four interaction flows

Four flows keep the system alive during validation and during Phase 4:

| Flow | Direction | What happens | Example |
|---|---|---|---|
| **Governance** | Rules → Agents | The Agent loads Rules as constraints before executing any Skill. | "project-context.md says TypeScript + Express. The Dev Agent can't use Python in any Skill." |
| **Execution** | Agents → Skills | The Agent receives a Skill, processes it within Rules, produces output. | "Dev Agent receives 'create endpoint', applies JSON format Rules, delivers output." |
| **Feedback** | Skills → Rules | A decision during a Skill that should be global gets escalated and becomes a Rule. | "The first endpoint Skill defines a pagination pattern. It gets promoted to a Rule for all Skills." |
| **Validation** | QA Agent → Everything | QA verifies each Agent respects Rules and each Skill produces conforming outputs. | "QA detects a Skill produces an endpoint without 'meta'. Violates Level 5 Rule. Rejected." |

### Diagnosing failures

When outputs don't match expectations, identify where the problem lies:

| Where's the problem? | Symptom | What to adjust |
|---|---|---|
| **The Rules** | Multiple Agents produce the same type of error across different Skills. Decisions are inconsistent with each other. | Refine Rules in project-context.md. A Rule is missing or too vague. |
| **An Agent** | One Agent fails across multiple Skills. Other Agents with similar Skills don't fail. | Review that Agent's identity, responsibilities, and limits. The Agent definition is incomplete. |
| **A Skill** | One output fails but the Agent works fine on other Skills. | Enrich the specific context of that Skill. It's missing information the Agent needs. |
| **The interaction** | Each Skill produces correct output individually. The whole doesn't work together. | Review dependencies between Skills and coherence between Rules and Skills. |

:::tip When outputs surprise you
The most revealing validation is when an output is technically correct but doesn't "feel right" to stakeholders. This usually signals a Rule that's missing, not an Agent that's broken. The Agent followed all Rules faithfully — the problem is that the Rules didn't capture something the team assumed was obvious. Make it explicit, add the Rule, and run the validation again.
:::
