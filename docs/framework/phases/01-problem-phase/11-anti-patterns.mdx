---
title: "Anti-patterns: what can go wrong"
sidebar_label: "Anti-patterns"
slug: /framework/phases/problem-phase/anti-patterns
description: "Recurring failure patterns in Problem Phase. Knowing them significantly increases the probability of detecting them in time."
sidebar_position: 5
tags: [phases, problem-phase]
---

import {AntiPatternAccordion, AntiPatternAccordionItem} from '@site/src/components/AntiPatternAccordion';

# Anti-patterns: what can go wrong

Over years of practice, we've identified recurring failure patterns in Problem Phase. Knowing them doesn't guarantee avoiding them, but it significantly increases the probability of detecting them in time.

<AntiPatternAccordion>
  <AntiPatternAccordionItem number={1} title="Organized Bias">
    **What it is:** The team enters discovery with a firm hypothesis and designs interviews, consciously or unconsciously, to confirm it. Questions are closed, interviewees are selected because they'll confirm the thesis, and data that contradicts it is discarded as exceptions.

    **How to detect it:** The final Problem Statement is identical to the starting hypothesis documented at the kick-off. No interview changed anything the team believed at the start.

    **How to prevent it:** Document hypotheses before discovery. Include at least one question in each interview that explicitly seeks to challenge the main hypothesis. Assign someone on the team the role of "devil's advocate" during synthesis.
  </AntiPatternAccordionItem>
  <AntiPatternAccordionItem number={2} title="Express Discovery">
    **What it is:** The team conducts 1-2 interviews, quickly confirms what it believed, and declares discovery complete in less than a week. The pressure to move forward wins over the need to go deeper.

    **How to detect it:** Fewer than 5 interviews conducted. The Synthesis Board has few notes and "obvious" patterns. There are no outliers or tensions.

    **How to prevent it:** Establish the minimum of 5 interviews as a non-negotiable rule. If after 5 interviews there are no tensions or surprises, the questions probably weren't the right ones.
  </AntiPatternAccordionItem>
  <AntiPatternAccordionItem number={3} title="Problem Statement by Committee">
    **What it is:** The Problem Statement is drafted in a meeting with too many people, diluted so everyone agrees, and ends up so generic it says nothing concrete. It's the result of optimizing for political consensus instead of precision.

    **How to detect it:** The Problem Statement contains phrases like "need to improve operational efficiency" or "optimize the user experience." If you could paste that Problem Statement into any project at any company and it would still sound plausible, it's too generic.

    **How to prevent it:** One person drafts, the team reviews. Don't draft as a group. The specificity test: Is this Problem Statement only true for this specific problem? If the answer is no, be more precise.
  </AntiPatternAccordionItem>
  <AntiPatternAccordionItem number={4} title="The Invisible Stakeholder">
    **What it is:** Direct users are interviewed but people who observe the problem from a different perspective are ignored: support, field sales, operations. The result is a correct but incomplete Problem Statement.

    **How to detect it:** The Problem Statement only reflects one perspective. There's no tension between different views of the problem. The Actor Map has empty roles.

    **How to prevent it:** Review the Actor Map and verify that at least one interviewee represents each relevant actor cluster.
  </AntiPatternAccordionItem>
  <AntiPatternAccordionItem number={5} title="The Solution Disguised as a Problem">
    **What it is:** The Problem Statement describes an absence of a solution instead of a real problem. "We don't have an inventory dashboard" is not a problem. "We lose sales because we don't know when a product runs out until the customer asks for it" is.

    **How to detect it:** If the Problem Statement contains the word "we need" followed by a tool or functionality, it's a solution in disguise.

    **How to prevent it:** Apply the multiple-solution test: if the problem is well-defined, it should be possible to imagine at least three different solutions. If it only admits one, you're probably describing the solution, not the problem.
  </AntiPatternAccordionItem>
  <AntiPatternAccordionItem number={6} title="Undefined Success">
    **What it is:** The Problem Statement perfectly describes the gap and its cost, but doesn't say what "solved" will look like. Each stakeholder assumes a different definition of success. The team builds the solution, delivers it, and three different people say it's not what they expected â€” each for a different reason.

    **How to detect it:** There's no explicit success criteria in the Problem Statement. Or there is one so vague it admits multiple interpretations: "improve inventory visibility" without defining what "improve" means or how it will be measured.

    **How to prevent it:** Before closing the Problem Statement, ask each key stakeholder: "If we solve this perfectly, how will you know? What will be different that you can observe or measure?" If the answers diverge, alignment is needed before moving forward.
  </AntiPatternAccordionItem>
  <AntiPatternAccordionItem number={7} title="Phantom Constraints">
    **What it is:** The team assumes constraints that don't exist ("the system doesn't allow that") or ignores constraints that do ("surely legal won't have a problem"). Both errors distort the solution space: the first limits it unnecessarily, the second produces unfeasible solutions.

    **How to detect it:** Documented constraints haven't been verified with the source. Nobody has asked IT whether the system really doesn't allow it. Nobody has consulted legal.

    **How to prevent it:** Every documented constraint needs a source. "According to the IT team, the ERP doesn't support real-time updates" is a verified constraint. "The system doesn't allow it" without a source is an assumption that may be wrong.
  </AntiPatternAccordionItem>
</AntiPatternAccordion>

## Quick reference

| Anti-pattern | Symptom | Root cause | Prevention |
|---|---|---|---|
| **Organized Bias** | Problem Statement identical to starting hypothesis | Interviews designed to confirm, not challenge | Document hypotheses before discovery; "devil's advocate" role |
| **Express Discovery** | Fewer than 5 interviews, no tensions | Pressure to move forward | Minimum 5 interviews as non-negotiable rule |
| **Problem Statement by Committee** | Generic statement valid for any company | Optimizing for political consensus | One person drafts, team reviews; specificity test |
| **Invisible Stakeholder** | Single-perspective Problem Statement | Key actors excluded from interviews | Verify Actor Map coverage before closing |
| **Solution Disguised as Problem** | Statement describes absence of a tool | Skipping from symptom to solution | Multiple-solution test: at least 3 solutions possible |
| **Undefined Success** | Each stakeholder assumes different definition | No explicit success criteria | Ask each stakeholder "how will you know it's solved?" |
| **Phantom Constraints** | Unverified constraints limiting solution space | Assumptions not checked with source | Every constraint needs a verified source |
